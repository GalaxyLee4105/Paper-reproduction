{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774846d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1029/3685004437.py:19: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1029/3685004437.py:133: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1029/3685004437.py:27: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 499)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16)           8000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           272         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           272         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           272         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           272         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           272         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           272         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           272         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           272         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            4000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 8)            4000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 16)        0           dense_2[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 8, 1)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 8, 1)         0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16)           0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16)           0           lambda_1[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            136         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            136         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8)            0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8)            0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "task0 (Dense)                   (None, 1)            9           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "task1 (Dense)                   (None, 1)            9           dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 74,466\n",
      "Trainable params: 74,466\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 199523 samples, validate on 49881 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 09:15:49.969689: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2025-08-20 09:15:49.987001: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2687995000 Hz\n",
      "2025-08-20 09:15:49.994061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x35e93a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-20 09:15:49.994108: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-08-20 09:15:50.006766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 09:15:50.990354: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-20 09:15:50.990674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32023a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-20 09:15:50.990706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-08-20 09:15:50.997492: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-20 09:15:50.997584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3060 Laptop GPU major: 8 minor: 6 memoryClockRate(GHz): 1.425\n",
      "pciBusID: 0000:01:00.0\n",
      "2025-08-20 09:15:50.998113: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:50.998604: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:50.998845: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:50.999255: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:50.999404: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:50.999854: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:51.000034: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-08-20 09:15:51.000072: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-08-20 09:15:51.000115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-08-20 09:15:51.000125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2025-08-20 09:15:51.000130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/glubuntu/miniconda3/envs/tf115py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "199523/199523 [==============================] - 7s 33us/step - loss: 6.4799 - task0_loss: 1.1427 - task1_loss: 5.3373 - task0_auc_roc: 0.5145 - task1_auc_roc: 0.5855 - val_loss: 2.6807 - val_task0_loss: 0.9949 - val_task1_loss: 1.6858 - val_task0_auc_roc: 0.4982 - val_task1_auc_roc: 0.8445\n",
      "Epoch 2/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 3.6055 - task0_loss: 1.0512 - task1_loss: 2.5543 - task0_auc_roc: 0.5096 - task1_auc_roc: 0.7631 - val_loss: 2.3903 - val_task0_loss: 0.9946 - val_task1_loss: 1.3957 - val_task0_auc_roc: 0.4969 - val_task1_auc_roc: 0.8566\n",
      "Epoch 3/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 2.6937 - task0_loss: 0.9866 - task1_loss: 1.7071 - task0_auc_roc: 0.5093 - task1_auc_roc: 0.8035 - val_loss: 2.3015 - val_task0_loss: 0.9936 - val_task1_loss: 1.3079 - val_task0_auc_roc: 0.5000 - val_task1_auc_roc: 0.8152\n",
      "Epoch 4/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 2.2530 - task0_loss: 0.9695 - task1_loss: 1.2834 - task0_auc_roc: 0.5071 - task1_auc_roc: 0.8018 - val_loss: 1.8081 - val_task0_loss: 0.9920 - val_task1_loss: 0.8161 - val_task0_auc_roc: 0.5004 - val_task1_auc_roc: 0.8025\n",
      "Epoch 5/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 2.0183 - task0_loss: 0.9644 - task1_loss: 1.0539 - task0_auc_roc: 0.5040 - task1_auc_roc: 0.7833 - val_loss: 1.7296 - val_task0_loss: 0.9902 - val_task1_loss: 0.7394 - val_task0_auc_roc: 0.5013 - val_task1_auc_roc: 0.7696\n",
      "Epoch 6/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 1.8795 - task0_loss: 0.9556 - task1_loss: 0.9239 - task0_auc_roc: 0.5031 - task1_auc_roc: 0.7762 - val_loss: 1.5624 - val_task0_loss: 0.9857 - val_task1_loss: 0.5767 - val_task0_auc_roc: 0.5007 - val_task1_auc_roc: 0.8646\n",
      "Epoch 7/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 1.7323 - task0_loss: 0.9515 - task1_loss: 0.7808 - task0_auc_roc: 0.4993 - task1_auc_roc: 0.7880 - val_loss: 1.5448 - val_task0_loss: 0.9780 - val_task1_loss: 0.5668 - val_task0_auc_roc: 0.4996 - val_task1_auc_roc: 0.8559\n",
      "Epoch 8/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 1.6555 - task0_loss: 0.9367 - task1_loss: 0.7188 - task0_auc_roc: 0.4993 - task1_auc_roc: 0.7960 - val_loss: 1.5018 - val_task0_loss: 0.9708 - val_task1_loss: 0.5310 - val_task0_auc_roc: 0.4985 - val_task1_auc_roc: 0.8755\n",
      "Epoch 9/50\n",
      "199523/199523 [==============================] - 5s 25us/step - loss: 1.5942 - task0_loss: 0.9213 - task1_loss: 0.6729 - task0_auc_roc: 0.4952 - task1_auc_roc: 0.8106 - val_loss: 1.4224 - val_task0_loss: 0.9547 - val_task1_loss: 0.4677 - val_task0_auc_roc: 0.4932 - val_task1_auc_roc: 0.9024\n",
      "Epoch 10/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 1.4950 - task0_loss: 0.8703 - task1_loss: 0.6246 - task0_auc_roc: 0.4797 - task1_auc_roc: 0.8220 - val_loss: 1.1400 - val_task0_loss: 0.6897 - val_task1_loss: 0.4503 - val_task0_auc_roc: 0.4190 - val_task1_auc_roc: 0.8981\n",
      "Epoch 11/50\n",
      "199523/199523 [==============================] - 4s 22us/step - loss: 1.3490 - task0_loss: 0.7716 - task1_loss: 0.5773 - task0_auc_roc: 0.4409 - task1_auc_roc: 0.8322 - val_loss: 0.9810 - val_task0_loss: 0.5798 - val_task1_loss: 0.4012 - val_task0_auc_roc: 0.4664 - val_task1_auc_roc: 0.9124\n",
      "Epoch 12/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 1.2372 - task0_loss: 0.6938 - task1_loss: 0.5435 - task0_auc_roc: 0.4738 - task1_auc_roc: 0.8474 - val_loss: 0.8701 - val_task0_loss: 0.4886 - val_task1_loss: 0.3815 - val_task0_auc_roc: 0.5702 - val_task1_auc_roc: 0.9166\n",
      "Epoch 13/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 1.1465 - task0_loss: 0.6349 - task1_loss: 0.5117 - task0_auc_roc: 0.4948 - task1_auc_roc: 0.8567 - val_loss: 0.8712 - val_task0_loss: 0.4958 - val_task1_loss: 0.3754 - val_task0_auc_roc: 0.5814 - val_task1_auc_roc: 0.9178\n",
      "Epoch 14/50\n",
      "199523/199523 [==============================] - 4s 22us/step - loss: 1.0751 - task0_loss: 0.5810 - task1_loss: 0.4941 - task0_auc_roc: 0.5178 - task1_auc_roc: 0.8611 - val_loss: 0.8375 - val_task0_loss: 0.4693 - val_task1_loss: 0.3682 - val_task0_auc_roc: 0.5917 - val_task1_auc_roc: 0.9202\n",
      "Epoch 15/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 1.0105 - task0_loss: 0.5396 - task1_loss: 0.4710 - task0_auc_roc: 0.5482 - task1_auc_roc: 0.8688 - val_loss: 0.7765 - val_task0_loss: 0.4450 - val_task1_loss: 0.3315 - val_task0_auc_roc: 0.6137 - val_task1_auc_roc: 0.9342\n",
      "Epoch 16/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.9138 - task0_loss: 0.4697 - task1_loss: 0.4441 - task0_auc_roc: 0.5775 - task1_auc_roc: 0.8886 - val_loss: 0.7535 - val_task0_loss: 0.4248 - val_task1_loss: 0.3287 - val_task0_auc_roc: 0.6255 - val_task1_auc_roc: 0.9355\n",
      "Epoch 17/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.8564 - task0_loss: 0.4298 - task1_loss: 0.4266 - task0_auc_roc: 0.6005 - task1_auc_roc: 0.8941 - val_loss: 0.7270 - val_task0_loss: 0.4092 - val_task1_loss: 0.3178 - val_task0_auc_roc: 0.6379 - val_task1_auc_roc: 0.9426\n",
      "Epoch 18/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.7655 - task0_loss: 0.3586 - task1_loss: 0.4069 - task0_auc_roc: 0.6694 - task1_auc_roc: 0.9013 - val_loss: 0.5660 - val_task0_loss: 0.2587 - val_task1_loss: 0.3073 - val_task0_auc_roc: 0.7946 - val_task1_auc_roc: 0.9456\n",
      "Epoch 19/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.7058 - task0_loss: 0.3150 - task1_loss: 0.3908 - task0_auc_roc: 0.7118 - task1_auc_roc: 0.9064 - val_loss: 0.5508 - val_task0_loss: 0.2402 - val_task1_loss: 0.3105 - val_task0_auc_roc: 0.8071 - val_task1_auc_roc: 0.9479\n",
      "Epoch 20/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.6774 - task0_loss: 0.2960 - task1_loss: 0.3814 - task0_auc_roc: 0.7296 - task1_auc_roc: 0.9105 - val_loss: 0.5273 - val_task0_loss: 0.2301 - val_task1_loss: 0.2972 - val_task0_auc_roc: 0.8183 - val_task1_auc_roc: 0.9503\n",
      "Epoch 21/50\n",
      "199523/199523 [==============================] - 5s 25us/step - loss: 0.6497 - task0_loss: 0.2801 - task1_loss: 0.3696 - task0_auc_roc: 0.7422 - task1_auc_roc: 0.9151 - val_loss: 0.5065 - val_task0_loss: 0.2179 - val_task1_loss: 0.2886 - val_task0_auc_roc: 0.8398 - val_task1_auc_roc: 0.9537\n",
      "Epoch 22/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.6216 - task0_loss: 0.2622 - task1_loss: 0.3593 - task0_auc_roc: 0.7605 - task1_auc_roc: 0.9192 - val_loss: 0.4928 - val_task0_loss: 0.2053 - val_task1_loss: 0.2875 - val_task0_auc_roc: 0.8453 - val_task1_auc_roc: 0.9561\n",
      "Epoch 23/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.6014 - task0_loss: 0.2549 - task1_loss: 0.3464 - task0_auc_roc: 0.7694 - task1_auc_roc: 0.9236 - val_loss: 0.4819 - val_task0_loss: 0.1996 - val_task1_loss: 0.2823 - val_task0_auc_roc: 0.8496 - val_task1_auc_roc: 0.9575\n",
      "Epoch 24/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.5848 - task0_loss: 0.2470 - task1_loss: 0.3378 - task0_auc_roc: 0.7753 - task1_auc_roc: 0.9273 - val_loss: 0.4676 - val_task0_loss: 0.1954 - val_task1_loss: 0.2722 - val_task0_auc_roc: 0.8546 - val_task1_auc_roc: 0.9579\n",
      "Epoch 25/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.5702 - task0_loss: 0.2405 - task1_loss: 0.3297 - task0_auc_roc: 0.7825 - task1_auc_roc: 0.9310 - val_loss: 0.4563 - val_task0_loss: 0.1832 - val_task1_loss: 0.2731 - val_task0_auc_roc: 0.8717 - val_task1_auc_roc: 0.9601\n",
      "Epoch 26/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.5641 - task0_loss: 0.2343 - task1_loss: 0.3298 - task0_auc_roc: 0.7897 - task1_auc_roc: 0.9327 - val_loss: 0.4642 - val_task0_loss: 0.1755 - val_task1_loss: 0.2886 - val_task0_auc_roc: 0.8760 - val_task1_auc_roc: 0.9611\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.5483 - task0_loss: 0.2267 - task1_loss: 0.3216 - task0_auc_roc: 0.8021 - task1_auc_roc: 0.9341 - val_loss: 0.4428 - val_task0_loss: 0.1723 - val_task1_loss: 0.2705 - val_task0_auc_roc: 0.8831 - val_task1_auc_roc: 0.9622\n",
      "Epoch 28/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.5354 - task0_loss: 0.2228 - task1_loss: 0.3127 - task0_auc_roc: 0.8046 - task1_auc_roc: 0.9373 - val_loss: 0.4446 - val_task0_loss: 0.1726 - val_task1_loss: 0.2721 - val_task0_auc_roc: 0.8812 - val_task1_auc_roc: 0.9633\n",
      "Epoch 29/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.5221 - task0_loss: 0.2177 - task1_loss: 0.3044 - task0_auc_roc: 0.8106 - task1_auc_roc: 0.9404 - val_loss: 0.4359 - val_task0_loss: 0.1714 - val_task1_loss: 0.2645 - val_task0_auc_roc: 0.8852 - val_task1_auc_roc: 0.9646\n",
      "Epoch 30/50\n",
      "199523/199523 [==============================] - 4s 22us/step - loss: 0.5131 - task0_loss: 0.2138 - task1_loss: 0.2993 - task0_auc_roc: 0.8146 - task1_auc_roc: 0.9427 - val_loss: 0.4349 - val_task0_loss: 0.1701 - val_task1_loss: 0.2648 - val_task0_auc_roc: 0.8864 - val_task1_auc_roc: 0.9651\n",
      "Epoch 31/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.5015 - task0_loss: 0.2103 - task1_loss: 0.2912 - task0_auc_roc: 0.8187 - task1_auc_roc: 0.9445 - val_loss: 0.4322 - val_task0_loss: 0.1690 - val_task1_loss: 0.2632 - val_task0_auc_roc: 0.8879 - val_task1_auc_roc: 0.9665\n",
      "Epoch 32/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4919 - task0_loss: 0.2073 - task1_loss: 0.2846 - task0_auc_roc: 0.8233 - task1_auc_roc: 0.9466 - val_loss: 0.4309 - val_task0_loss: 0.1674 - val_task1_loss: 0.2635 - val_task0_auc_roc: 0.8873 - val_task1_auc_roc: 0.9673\n",
      "Epoch 33/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4859 - task0_loss: 0.2058 - task1_loss: 0.2801 - task0_auc_roc: 0.8255 - task1_auc_roc: 0.9482 - val_loss: 0.4187 - val_task0_loss: 0.1661 - val_task1_loss: 0.2526 - val_task0_auc_roc: 0.8909 - val_task1_auc_roc: 0.9687\n",
      "Epoch 34/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4753 - task0_loss: 0.2024 - task1_loss: 0.2729 - task0_auc_roc: 0.8295 - task1_auc_roc: 0.9501 - val_loss: 0.4230 - val_task0_loss: 0.1668 - val_task1_loss: 0.2562 - val_task0_auc_roc: 0.8904 - val_task1_auc_roc: 0.9696\n",
      "Epoch 35/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4718 - task0_loss: 0.2017 - task1_loss: 0.2702 - task0_auc_roc: 0.8316 - task1_auc_roc: 0.9516 - val_loss: 0.4181 - val_task0_loss: 0.1645 - val_task1_loss: 0.2536 - val_task0_auc_roc: 0.8927 - val_task1_auc_roc: 0.9703\n",
      "Epoch 36/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4632 - task0_loss: 0.2000 - task1_loss: 0.2631 - task0_auc_roc: 0.8343 - task1_auc_roc: 0.9532 - val_loss: 0.4113 - val_task0_loss: 0.1629 - val_task1_loss: 0.2484 - val_task0_auc_roc: 0.8933 - val_task1_auc_roc: 0.9717\n",
      "Epoch 37/50\n",
      "199523/199523 [==============================] - 5s 25us/step - loss: 0.4570 - task0_loss: 0.1988 - task1_loss: 0.2582 - task0_auc_roc: 0.8351 - task1_auc_roc: 0.9553 - val_loss: 0.4274 - val_task0_loss: 0.1629 - val_task1_loss: 0.2645 - val_task0_auc_roc: 0.8942 - val_task1_auc_roc: 0.9709\n",
      "Epoch 38/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4482 - task0_loss: 0.1958 - task1_loss: 0.2524 - task0_auc_roc: 0.8396 - task1_auc_roc: 0.9568 - val_loss: 0.4025 - val_task0_loss: 0.1603 - val_task1_loss: 0.2422 - val_task0_auc_roc: 0.8977 - val_task1_auc_roc: 0.9720\n",
      "Epoch 39/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4402 - task0_loss: 0.1930 - task1_loss: 0.2472 - task0_auc_roc: 0.8424 - task1_auc_roc: 0.9591 - val_loss: 0.3937 - val_task0_loss: 0.1605 - val_task1_loss: 0.2333 - val_task0_auc_roc: 0.8973 - val_task1_auc_roc: 0.9740\n",
      "Epoch 40/50\n",
      "199523/199523 [==============================] - 4s 21us/step - loss: 0.4279 - task0_loss: 0.1917 - task1_loss: 0.2362 - task0_auc_roc: 0.8446 - task1_auc_roc: 0.9630 - val_loss: 0.3805 - val_task0_loss: 0.1594 - val_task1_loss: 0.2210 - val_task0_auc_roc: 0.8989 - val_task1_auc_roc: 0.9737\n",
      "Epoch 41/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.4050 - task0_loss: 0.1857 - task1_loss: 0.2193 - task0_auc_roc: 0.8579 - task1_auc_roc: 0.9684 - val_loss: 0.3849 - val_task0_loss: 0.1595 - val_task1_loss: 0.2254 - val_task0_auc_roc: 0.8997 - val_task1_auc_roc: 0.9737\n",
      "Epoch 42/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.3911 - task0_loss: 0.1799 - task1_loss: 0.2112 - task0_auc_roc: 0.8696 - task1_auc_roc: 0.9708 - val_loss: 0.4029 - val_task0_loss: 0.1599 - val_task1_loss: 0.2431 - val_task0_auc_roc: 0.9008 - val_task1_auc_roc: 0.9753\n",
      "Epoch 43/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.3823 - task0_loss: 0.1774 - task1_loss: 0.2049 - task0_auc_roc: 0.8730 - task1_auc_roc: 0.9725 - val_loss: 0.3731 - val_task0_loss: 0.1585 - val_task1_loss: 0.2147 - val_task0_auc_roc: 0.9012 - val_task1_auc_roc: 0.9766\n",
      "Epoch 44/50\n",
      "199523/199523 [==============================] - 4s 22us/step - loss: 0.3795 - task0_loss: 0.1764 - task1_loss: 0.2031 - task0_auc_roc: 0.8742 - task1_auc_roc: 0.9730 - val_loss: 0.3859 - val_task0_loss: 0.1590 - val_task1_loss: 0.2270 - val_task0_auc_roc: 0.9015 - val_task1_auc_roc: 0.9765\n",
      "Epoch 45/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.3767 - task0_loss: 0.1757 - task1_loss: 0.2010 - task0_auc_roc: 0.8760 - task1_auc_roc: 0.9739 - val_loss: 0.3640 - val_task0_loss: 0.1566 - val_task1_loss: 0.2074 - val_task0_auc_roc: 0.9045 - val_task1_auc_roc: 0.9771\n",
      "Epoch 46/50\n",
      "199523/199523 [==============================] - 5s 23us/step - loss: 0.3695 - task0_loss: 0.1745 - task1_loss: 0.1951 - task0_auc_roc: 0.8764 - task1_auc_roc: 0.9750 - val_loss: 0.3943 - val_task0_loss: 0.1568 - val_task1_loss: 0.2375 - val_task0_auc_roc: 0.9045 - val_task1_auc_roc: 0.9765\n",
      "Epoch 47/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.3656 - task0_loss: 0.1716 - task1_loss: 0.1940 - task0_auc_roc: 0.8800 - task1_auc_roc: 0.9755 - val_loss: 0.4021 - val_task0_loss: 0.1565 - val_task1_loss: 0.2455 - val_task0_auc_roc: 0.9054 - val_task1_auc_roc: 0.9765\n",
      "Epoch 48/50\n",
      "199523/199523 [==============================] - 5s 24us/step - loss: 0.3586 - task0_loss: 0.1718 - task1_loss: 0.1868 - task0_auc_roc: 0.8803 - task1_auc_roc: 0.9771 - val_loss: 0.3799 - val_task0_loss: 0.1562 - val_task1_loss: 0.2237 - val_task0_auc_roc: 0.9080 - val_task1_auc_roc: 0.9772\n",
      "Epoch 49/50\n",
      "199523/199523 [==============================] - 5s 26us/step - loss: 0.3493 - task0_loss: 0.1697 - task1_loss: 0.1796 - task0_auc_roc: 0.8846 - task1_auc_roc: 0.9789 - val_loss: 0.3707 - val_task0_loss: 0.1543 - val_task1_loss: 0.2164 - val_task0_auc_roc: 0.9112 - val_task1_auc_roc: 0.9774\n",
      "Epoch 50/50\n",
      "199523/199523 [==============================] - 5s 25us/step - loss: 0.3429 - task0_loss: 0.1691 - task1_loss: 0.1737 - task0_auc_roc: 0.8866 - task1_auc_roc: 0.9797 - val_loss: 0.3602 - val_task0_loss: 0.1522 - val_task1_loss: 0.2080 - val_task0_auc_roc: 0.9150 - val_task1_auc_roc: 0.9786\n",
      "49881/49881 [==============================] - 5s 91us/step\n",
      "Test results: [0.36080186505865663, 0.15153816526179917, 0.2092636996259815, 0.8634866046783618, 0.978534702676958]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Input, Dense, Dropout, Multiply, Softmax, Lambda, Concatenate\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(3)\n",
    "np.random.seed(3)\n",
    "\n",
    "batch_size = 1024\n",
    "seed = 3\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "def auc_roc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_func(fallback_auc, (y_true, y_pred), tf.double)\n",
    "\n",
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "\n",
    "def data_preparation():\n",
    "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
    "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
    "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
    "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
    "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
    "\n",
    "    train_df = pd.read_csv('./DATA/census-income.data', delimiter=',', header=None, index_col=None, names=column_names)\n",
    "    test_df = pd.read_csv('./DATA/census-income.test', delimiter=',', header=None, index_col=None, names=column_names)\n",
    "\n",
    "    label_columns = ['income_50k', 'marital_stat']\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    train_transformed = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    test_transformed = pd.get_dummies(test_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    train_labels = train_df[label_columns]\n",
    "    test_labels = test_df[label_columns]\n",
    "\n",
    "    test_transformed['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
    "\n",
    "    train_income = to_categorical((train_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    train_marital = to_categorical((train_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    other_income = to_categorical((test_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    other_marital = to_categorical((test_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "\n",
    "    dict_outputs = {'income': train_income.shape[1], 'marital': train_marital.shape[1]}\n",
    "    dict_train_labels = {'income': train_income, 'marital': train_marital}\n",
    "    dict_other_labels = {'income': other_income, 'marital': other_marital}\n",
    "\n",
    "    validation_indices = test_transformed.sample(frac=0.5, replace=False, random_state=seed).index\n",
    "    test_indices = list(set(test_transformed.index) - set(validation_indices))\n",
    "    validation_data = test_transformed.iloc[validation_indices]\n",
    "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    test_data = test_transformed.iloc[test_indices]\n",
    "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    train_data = train_transformed\n",
    "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label, dict_outputs\n",
    "\n",
    "def build_mmoe(input_dim, num_experts=6, experts_out=16, experts_hidden=32, towers_hidden=8, num_tasks=2):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # Experts\n",
    "    experts = []\n",
    "    for i in range(num_experts):\n",
    "        x = Dense(experts_hidden, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(experts_out)(x)\n",
    "        experts.append(x)\n",
    "\n",
    "    # 堆叠 expert 输出: (batch, num_experts, experts_out)\n",
    "    expert_stack = Lambda(lambda x: K.stack(x, axis=1))(experts)\n",
    "\n",
    "    outputs = []\n",
    "    for t in range(num_tasks):\n",
    "        # gate (batch, num_experts)\n",
    "        gate = Dense(num_experts, activation='softmax')(inputs)\n",
    "        gate = Lambda(lambda g: K.expand_dims(g, axis=-1))(gate)  # (batch, num_experts, 1)\n",
    "\n",
    "        # 加权求和 experts\n",
    "        tower_input = Lambda(lambda z: K.sum(z[0] * z[1], axis=1))([expert_stack, gate])\n",
    "\n",
    "        # Tower\n",
    "        tower = Dense(towers_hidden, activation='relu')(tower_input)\n",
    "        tower = Dropout(0.4)(tower)\n",
    "        tower_output = Dense(1, activation='sigmoid', name=f'task{t}')(tower)\n",
    "        outputs.append(tower_output)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 数据准备\n",
    "train_data, train_label, val_data, val_label, test_data, test_label, output_info = data_preparation()\n",
    "input_dim = train_data.shape[1]\n",
    "\n",
    "# 建模\n",
    "model = build_mmoe(input_dim = input_dim, num_experts = 8, experts_out = 16,\n",
    "                   experts_hidden = 16, towers_hidden = 8, num_tasks = 2)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[auc_roc]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 训练\n",
    "history = model.fit(train_data.values,\n",
    "                    {'task0': train_label[0][:,1], 'task1': train_label[1][:,1]},\n",
    "                    validation_data=(val_data.values, {'task0': val_label[0][:,1], 'task1': val_label[1][:,1]}),\n",
    "                    epochs = 50,\n",
    "                    batch_size = batch_size)\n",
    "\n",
    "# 测试\n",
    "res = model.evaluate(test_data.values, {'task0': test_label[0][:,1], 'task1': test_label[1][:,1]})\n",
    "print(\"Test results:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ce633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf115)",
   "language": "python",
   "name": "tf115py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
